# scripts/create_tts.py
import logging
import os
import asyncio
import textwrap
import random
import time
from openai import OpenAI
from pydub import AudioSegment
import edge_tts
from utils import get_path

logger = logging.getLogger(__name__)

# =========================================================
# âš™ï¸ Cáº¤U HÃŒNH GIá»ŒNG Äá»ŒC
# =========================================================
EDGE_VOICES = [
    "en-US-ChristopherNeural", 
    "en-US-EricNeural",        
    "en-US-GuyNeural",         
    "en-US-RogerNeural"        
]

USE_OPENAI_BACKUP = True
SPEED_MULTIPLIER = 1.15

# =========================================================
# ğŸ§¹ HÃ€M LÃ€M Sáº CH VÃ€ CHUáº¨N HÃ“A Ká»ŠCH Báº¢N
# =========================================================
def clean_and_validate_script(text):
    if not text: return ""
    # Loáº¡i bá» cÃ¡c tag ká»¹ thuáº­t Ä‘á»ƒ TTS khÃ´ng Ä‘á»c lÃªn
    text = text.replace('**', '').replace('__', '')
    text = os.linesep.join([line for line in text.splitlines() if not line.strip().startswith(('[', 'Visual', 'Sound', 'Scene'))])
    return text.strip()

# =========================================================
# ğŸ™ï¸ CORE TTS LOGIC (EDGE-TTS)
# =========================================================
async def generate_with_edge(chunks, episode_id):
    combined = AudioSegment.empty()
    voice = random.choice(EDGE_VOICES)
    
    for i, chunk in enumerate(chunks):
        temp_path = get_path("assets", "temp", f"{episode_id}_part_{i}.mp3")
        try:
            communicate = edge_tts.Communicate(chunk, voice)
            await communicate.save(temp_path)
            
            segment = AudioSegment.from_mp3(temp_path)
            combined += segment
            if os.path.exists(temp_path): os.remove(temp_path)
        except Exception as e:
            logger.error(f"âš ï¸ Lá»—i Edge-TTS táº¡i chunk {i}: {e}")
            return None
    return combined

# =========================================================
# ğŸš€ HÃ€M CHÃNH: CREATE TTS (Cáº¬P NHáº¬T CHO 5 SHORTS)
# =========================================================
def create_tts(text, episode_id, mode="long", short_index=None):
    """
    Táº¡o giá»ng Ä‘á»c cho Video DÃ i hoáº·c Video Shorts (Part 1-5).
    """
    if not text:
        logger.error("âŒ KhÃ´ng cÃ³ ná»™i dung text Ä‘á»ƒ táº¡o TTS.")
        return None

    full_text = clean_and_validate_script(text)
    
    # Chia nhá» text Ä‘á»ƒ trÃ¡nh lá»—i timeout API (750 kÃ½ tá»±/chunk)
    chunk_size = 750 
    chunks = textwrap.wrap(full_text, width=chunk_size, break_long_words=False)
    
    # Cháº¡y loop async Ä‘á»ƒ táº¡o audio
    loop = asyncio.get_event_loop()
    combined_audio = loop.run_until_complete(generate_with_edge(chunks, episode_id))
    
    # Fallback sang OpenAI náº¿u Edge lá»—i (náº¿u cáº¥u hÃ¬nh cho phÃ©p)
    if combined_audio is None and USE_OPENAI_BACKUP:
        logger.warning("ğŸ”„ Äang thá»­ dÃ¹ng OpenAI Backup...")
        # (Giáº£ Ä‘á»‹nh hÃ m generate_with_openai Ä‘Ã£ cÃ³ sáºµn trong dá»± Ã¡n cá»§a báº¡n)
        # combined_audio = generate_with_openai(chunks, episode_id)

    if combined_audio is None:
        logger.error("âŒ Tháº¥t báº¡i trong viá»‡c táº¡o Ã¢m thanh.")
        return None

    # TÄƒng tá»‘c Ä‘á»™ giá»ng Ä‘á»c theo SPEED_MULTIPLIER
    if SPEED_MULTIPLIER != 1.0:
        rate = combined_audio.frame_rate
        combined_audio = combined_audio._spawn(combined_audio.raw_data, overrides={
            "frame_rate": int(rate * SPEED_MULTIPLIER)
        }).set_frame_rate(rate)

    # Äá»ŠNH DANH FILE OUTPUT (QUAN TRá»ŒNG: TrÃ¡nh ghi Ä‘Ã¨)
    if mode == "short":
        suffix = f"short_{short_index}" if short_index else "short"
    else:
        suffix = "long"

    output_path = get_path("data", "audio", f"{episode_id}_{suffix}.mp3")
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    
    combined_audio.export(output_path, format="mp3")
    logger.info(f"âœ… ÄÃ£ lÆ°u Audio {mode.upper()}: {output_path}")
    
    return output_path
