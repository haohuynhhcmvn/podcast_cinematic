# scripts/create_tts.py
import logging
import os
import textwrap
from openai import OpenAI
from pydub import AudioSegment
from utils import get_path

logger = logging.getLogger(__name__)

# Cáº¥u hÃ¬nh
TTS_MODEL = "tts-1"
VOICE = "onyx" # Giá»ng tráº§m, nam tÃ­nh (Ráº¥t há»£p kÃªnh lá»‹ch sá»­/huyá»n thoáº¡i)
SPEED_MULTIPLIER = 1.15 # TÄƒng tá»‘c nháº¹ Ä‘á»ƒ bá»›t buá»“n ngá»§

# =========================================================
# ğŸ§¹ HÃ€M Lá»ŒC Sáº N Ká»ŠCH Báº¢N (QUAN TRá»ŒNG)
# =========================================================
def clean_and_validate_script(text):
    """
    Loáº¡i bá» cÃ¡c dÃ²ng tiÃªu Ä‘á», meta-data thá»«a (VD: 'Biography Script...', 'Title:')
    Ä‘á»ƒ trÃ¡nh viá»‡c AI Ä‘á»c thÃ nh tiáº¿ng gÃ¢y máº¥t chuyÃªn nghiá»‡p.
    """
    if not text: return ""
    
    lines = text.split('\n')
    cleaned_lines = []
    
    # Danh sÃ¡ch tá»« khÃ³a rÃ¡c thÆ°á»ng xuáº¥t hiá»‡n á»Ÿ dÃ²ng Ä‘áº§u do GPT sinh ra
    garbage_keywords = [
        "script", "biography", "title:", "host:", "narrator:", 
        "intro:", "outro:", "music:", "visual:", "scene:", 
        "fades in", "camera", "voiceover"
    ]
    
    for i, line in enumerate(lines):
        clean_line = line.strip()
        
        # Bá» dÃ²ng trá»‘ng
        if not clean_line: 
            continue
            
        # CHá»ˆ KIá»‚M TRA Ká»¸ 5 DÃ’NG Äáº¦U TIÃŠN (Header)
        if i < 5:
            lower_line = clean_line.lower()
            
            # 1. Náº¿u dÃ²ng chá»©a tá»« khÃ³a rÃ¡c (VD: "biography script of...")
            if any(kw in lower_line for kw in garbage_keywords):
                logger.warning(f"ğŸ—‘ï¸ ÄÃ£ xÃ³a dÃ²ng rÃ¡c Ä‘áº§u file: '{clean_line}'")
                continue
                
            # 2. Náº¿u dÃ²ng quÃ¡ ngáº¯n (Kiá»ƒu tiÃªu Ä‘á») mÃ  khÃ´ng pháº£i cÃ¢u hoÃ n chá»‰nh (khÃ´ng cÃ³ dáº¥u cháº¥m)
            # VD: "ALEXANDER THE GREAT" -> XÃ³a Ä‘á»ƒ vÃ o tháº³ng Hook
            if len(clean_line.split()) < 6 and not clean_line.endswith(('.', '!', '?')):
                 logger.warning(f"ğŸ—‘ï¸ ÄÃ£ xÃ³a tiÃªu Ä‘á» ngáº¯n: '{clean_line}'")
                 continue
                 
        cleaned_lines.append(clean_line)
        
    return "\n".join(cleaned_lines)

# =========================================================
# ğŸ§ HÃ€M Táº O TTS CHÃNH
# =========================================================
def create_tts(script_path, episode_id, mode="long"):
    try:
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            logger.error("âŒ Missing OPENAI_API_KEY.")
            return None

        client = OpenAI(api_key=api_key)

        # 1. Äá»c ná»™i dung file
        if not os.path.exists(script_path):
            logger.error(f"âŒ Script not found: {script_path}")
            return None
            
        with open(script_path, "r", encoding="utf-8") as f:
            raw_text = f.read().strip()

        # 2. [FIX] LÃ€M Sáº CH Ká»ŠCH Báº¢N TRÆ¯á»šC KHI Gá»¬I CHO AI
        full_text = clean_and_validate_script(raw_text)
        
        if not full_text:
            logger.error("âŒ Ká»‹ch báº£n rá»—ng sau khi lá»c.")
            return None

        # 3. Chia nhá» (Chunking) thÃ´ng minh Ä‘á»ƒ trÃ¡nh giá»›i háº¡n API
        # DÃ¹ng textwrap Ä‘á»ƒ khÃ´ng cáº¯t Ä‘Ã´i tá»«
        chunk_size = 3000
        chunks = textwrap.wrap(full_text, width=chunk_size, break_long_words=False, replace_whitespace=False)

        # 4. Gá»i API OpenAI TTS
        combined_audio = AudioSegment.empty()
        
        logger.info(f"ğŸ™ï¸ Äang táº¡o TTS ({len(chunks)} pháº§n) - Mode: {mode}...")
        
        for i, chunk in enumerate(chunks):
            try:
                response = client.audio.speech.create(
                    model=TTS_MODEL,
                    voice=VOICE,
                    input=chunk
                )
                
                # LÆ°u táº¡m tá»«ng pháº§n
                temp_chunk_path = get_path("assets", "temp", f"{episode_id}_chunk_{i}.mp3")
                os.makedirs(os.path.dirname(temp_chunk_path), exist_ok=True)
                
                response.stream_to_file(temp_chunk_path)
                
                # GhÃ©p vÃ o audio tá»•ng
                segment = AudioSegment.from_file(temp_chunk_path)
                combined_audio += segment
                
                # Dá»n dáº¹p ngay
                os.remove(temp_chunk_path)
                
            except Exception as e:
                logger.error(f"âš ï¸ Lá»—i chunk {i}: {e}")
                continue

        if len(combined_audio) == 0:
            return None

        # 5. [FIX] TÄ‚NG Tá»C Äá»˜ (SPEED UP) 1.15x
        # Ká»¹ thuáº­t: TÄƒng frame rate giáº£ (nhanh + cao Ä‘á»™ tÄƒng) -> Set láº¡i frame rate gá»‘c
        if SPEED_MULTIPLIER != 1.0:
            original_rate = combined_audio.frame_rate
            new_rate = int(original_rate * SPEED_MULTIPLIER)
            
            # Hack tá»‘c Ä‘á»™ báº±ng pydub
            combined_audio = combined_audio._spawn(combined_audio.raw_data, overrides={
                "frame_rate": new_rate
            })
            combined_audio = combined_audio.set_frame_rate(original_rate)
            
            logger.info(f"âš¡ ÄÃ£ tÄƒng tá»‘c Ä‘á»™ audio: {SPEED_MULTIPLIER}x")

        # 6. Xuáº¥t file cuá»‘i cÃ¹ng
        suffix = "long" if mode == "long" else "short"
        output_path = get_path("data", "audio", f"{episode_id}_{suffix}.mp3")
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        
        combined_audio.export(output_path, format="mp3")
        logger.info(f"âœ… TTS HoÃ n táº¥t: {output_path}")
        
        return output_path

    except Exception as e:
        logger.error(f"âŒ Lá»—i Create TTS: {e}", exc_info=True)
        return None
