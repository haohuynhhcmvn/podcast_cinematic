# === scripts/create_video.py ===
import logging
import os
import numpy as np
import math
from PIL import Image, ImageEnhance, ImageFilter, ImageDraw, ImageChops
import PIL.Image

# --- [FIX QUAN TR·ªåNG] V√Å L·ªñI T∆Ø∆†NG TH√çCH PILLOW/MOVIEPY ---
if not hasattr(PIL.Image, 'ANTIALIAS'):
    if hasattr(PIL.Image, 'Resampling') and hasattr(PIL.Image.Resampling, 'LANCZOS'):
        PIL.Image.ANTIALIAS = PIL.Image.Resampling.LANCZOS
    elif hasattr(PIL.Image, 'LANCZOS'):
        PIL.Image.ANTIALIAS = PIL.Image.LANCZOS
# -----------------------------------------------------------

from moviepy.editor import (
    AudioFileClip, VideoFileClip, ImageClip, ColorClip,
    CompositeVideoClip, TextClip, concatenate_videoclips,
    vfx
)
from utils import get_path

logger = logging.getLogger(__name__)

OUTPUT_WIDTH = 1280
OUTPUT_HEIGHT = 720

# ============================================================
# üé® H√ÄM 1: X·ª¨ L√ù ·∫¢NH NH√ÇN V·∫¨T (ULTRA SOFT BLEND - X√ìA VI·ªÄN)
# ============================================================
def create_static_overlay_image(char_path, width=OUTPUT_WIDTH, height=OUTPUT_HEIGHT):
    logger.info("   (LOG-BG): X·ª≠ l√Ω nh√¢n v·∫≠t AI (Ultra Soft Blend & No Black Edges)...")
    # T·∫°o canvas ho√†n to√†n trong su·ªët
    final_overlay = Image.new("RGBA", (width, height), (0, 0, 0, 0))
    
    if char_path and os.path.exists(char_path):
        try:
            char_img = Image.open(char_path).convert("RGBA")
            
            # T√≠nh to√°n t·ª∑ l·ªá ƒë·ªÉ ·∫£nh ph·ªß k√≠n chi·ªÅu cao video
            new_char_h = height 
            aspect_ratio = char_img.width / char_img.height
            new_char_w = int(new_char_h * aspect_ratio)
            char_img = char_img.resize((new_char_w, new_char_h), Image.LANCZOS)
            
            # --- K·ª∏ THU·∫¨T L√ÄM M·ªú VI·ªÄN T·ªêI ƒêA ---
            alpha = char_img.getchannel("A")
            # Thu nh·ªè v√πng hi·ªÉn th·ªã ƒë·ªÉ v·∫øt m·ªù ƒÉn s√¢u v√†o trong
            eroded_mask = alpha.filter(ImageFilter.MinFilter(25))
            # L√†m nh√≤e c·ª±c m·∫°nh (GaussianBlur 60-80) ƒë·ªÉ tan bi·∫øn v√†o n·ªÅn
            soft_edge_mask = eroded_mask.filter(ImageFilter.GaussianBlur(70))
            
            # Gi·∫£m ƒë·ªô ƒë·∫≠m to√†n th√¢n (Opacity ~75%) ƒë·ªÉ l√†m n·ªïi b·∫≠t n·ªÅn tƒ©nh xuy√™n th·∫•u
            opacity_layer = Image.new("L", soft_edge_mask.size, 190)
            final_mask = ImageChops.multiply(soft_edge_mask, opacity_layer)

            # Canh gi·ªØa nh√¢n v·∫≠t
            paste_x = (width - new_char_w) // 2 
            final_overlay.paste(char_img, (paste_x, 0), mask=final_mask)
            
        except Exception as e:
            logger.error(f"‚ùå L·ªói Pillow: {e}")

    overlay_path = get_path('assets', 'temp', "char_blend_mix.png")
    os.makedirs(os.path.dirname(overlay_path), exist_ok=True)
    final_overlay.save(overlay_path, format="PNG") 
    return overlay_path

# ============================================================
# üé• H√ÄM 2: T·∫†O N·ªÄN HYBRID (PH·ªêI C·∫¢NH ƒêA T·∫¶NG)
# ============================================================
def make_hybrid_video_background(video_path, static_bg_path, char_overlay_path, duration, width=OUTPUT_WIDTH, height=OUTPUT_HEIGHT):
    try:
        layers = []

        # 1. L·ªöP ƒê√ÅY: ·∫¢NH N·ªÄN Tƒ®NH (ƒê√£ tƒÉng t∆∞∆°ng ph·∫£n ƒë·ªÉ l√†m n·ªïi b·∫≠t kh√¥ng gian)
        if static_bg_path and os.path.exists(static_bg_path):
            img_clip = ImageClip(static_bg_path).set_duration(duration)
            img_clip = img_clip.resize(height=height).crop(x_center=img_clip.w/2, width=width)
            # L√†m t·ªëi n·ªÅn (0.85) v√† tƒÉng n√©t (0.3) ƒë·ªÉ t√¥n l·ªõp nh√¢n v·∫≠t m·ªù ·∫£o ph√≠a tr√™n
            img_clip = img_clip.fx(vfx.colorx, factor=0.85).fx(vfx.lum_contrast, contrast=0.3)
            layers.append(img_clip)

        # 2. L·ªöP GI·ªÆA: NH√ÇN V·∫¨T ƒê√É BLEND VI·ªÄN
        if os.path.exists(char_overlay_path):
            char_clip = ImageClip(char_overlay_path).set_duration(duration)
            layers.append(char_clip)

        # 3. L·ªöP PH·ª¶: VIDEO ƒê·ªòNG (M√¢y/Kh√≥i bay m·ªù - Ch·∫ø ƒë·ªô Kh√¥ng √¢m thanh)
        try:
            # audio=False gi√∫p render nhanh k·ªãch s√†n v√¨ b·ªè qua x·ª≠ l√Ω audio stream
            temp_clip = VideoFileClip(video_path, audio=False, target_resolution=(height, width))
            if temp_clip.duration < duration:
                num_loops = math.ceil(duration / temp_clip.duration)
                temp_clip = temp_clip.fx(vfx.loop, duration=duration)
            
            video_layer = temp_clip.subclip(0, duration).set_opacity(0.35).fx(vfx.colorx, factor=1.1)
            layers.append(video_layer)
        except:
            pass

        return CompositeVideoClip(layers, size=(width, height)).set_duration(duration)
    except Exception as e:
        logger.error(f"‚ùå L·ªói t·ªïng h·ª£p: {e}")
        return ColorClip(size=(width, height), color=(15, 15, 15), duration=duration)

# ============================================================
# üé¨ H√ÄM CH√çNH: CREATE VIDEO (RENDER PIPELINE)
# ============================================================
def create_video(audio_path, episode_id, custom_image_path=None, title_text=""):
    try:
        audio = AudioFileClip(audio_path)
        duration = audio.duration
        
        # Smart Picker: Ch·ªçn n·ªÅn tƒ©nh theo ID (ID_bg.png) ho·∫∑c m·∫∑c ƒë·ªãnh
        custom_bg = get_path('assets', 'images', f"{episode_id}_bg.png")
        static_bg_path = custom_bg if os.path.exists(custom_bg) else get_path('assets', 'images', 'default_background.png')
        
        # Ti·ªÅn x·ª≠ l√Ω nh√¢n v·∫≠t (L√†m m·ªù vi·ªÅn t·ªëi ƒëa)
        char_overlay_path = create_static_overlay_image(custom_image_path)
        base_video_path = get_path('assets', 'video', 'long_background.mp4') 
        
        # T·ªïng h·ª£p n·ªÅn ph·ªëi c·∫£nh 3 l·ªõp
        background_clip = make_hybrid_video_background(base_video_path, static_bg_path, char_overlay_path, duration)

        # üñãÔ∏è L·ªöP TI√äU ƒê·ªÄ (G√ìC TR√ÅI TR√äN)
        title_layer = None
        if title_text:
            try:
                title_layer = TextClip(
                    title_text.upper(), 
                    fontsize=50, font='DejaVu-Sans-Bold', color='#FFD700', 
                    stroke_color='black', stroke_width=2,
                    method='caption', align='West', size=(OUTPUT_WIDTH * 0.6, None)
                ).set_position((50, 40)).set_duration(duration) # C√°ch tr√°i 50, tr√™n 40
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Title Error: {e}")

        # Composing Final
        final_layers = [background_clip]
        if title_layer: final_layers.append(title_layer)
        
        final_video = CompositeVideoClip(final_layers, size=(OUTPUT_WIDTH, OUTPUT_HEIGHT)).set_audio(audio)
        
        output_path = get_path('outputs', 'video', f"{episode_id}_video.mp4")
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        
        # RENDER T·ªêI ∆ØU: 15 FPS gi√∫p GitHub Actions ch·∫°y nhanh g·∫•p ƒë√¥i b·∫£n 30 FPS
        logger.info(f"üöÄ RENDER START (Cinematic Optimized): {output_path}")
        final_video.write_videofile(
            output_path, fps=15, codec="libx264", audio_codec="aac", 
            preset="ultrafast", threads=4, ffmpeg_params=["-crf", "26"], logger='bar' 
        )
        
        # Cleanup gi·∫£i ph√≥ng RAM
        final_video.close()
        audio.close()
        return output_path

    except Exception as e:
        logger.error(f"‚ùå FATAL ERROR: {e}", exc_info=True)
        return False
